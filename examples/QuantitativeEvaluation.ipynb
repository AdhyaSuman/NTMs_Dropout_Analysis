{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cad4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T09:12:36.243752Z",
     "start_time": "2022-10-15T09:12:36.235053Z"
    }
   },
   "source": [
    "# Download the repo from https://github.com/AdhyaSuman/NTMs_Dropout_Analysis and run the setup file to install OCTIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9803b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-26T14:54:10.324157Z",
     "start_time": "2023-02-26T14:54:10.321592Z"
    }
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145fa5f3",
   "metadata": {},
   "source": [
    "Run the setup.py file using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2a8ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-26T14:54:14.784963Z",
     "start_time": "2023-02-26T14:54:11.483648Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install -e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cb257",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826b641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-26T14:54:22.068192Z",
     "start_time": "2023-02-26T14:54:14.818993Z"
    }
   },
   "outputs": [],
   "source": [
    "from octis.dataset.dataset import Dataset\n",
    "\n",
    "#Import models:\n",
    "from octis.models.ETM import ETM\n",
    "from octis.models.CTM import CTM\n",
    "from octis.models.ProdLDA import ProdLDA\n",
    "\n",
    "#Import coherence metric:\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "\n",
    "#Import TD metrics:\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity, InvertedRBO\n",
    "\n",
    "#Import Classfication metric:\n",
    "from octis.evaluation_metrics.classification_metrics import AccuracyScore\n",
    "\n",
    "import random, torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8e185",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c19dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-26T14:54:28.157294Z",
     "start_time": "2023-02-26T14:54:28.153447Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data_dir = './preprocessed_datasets'\n",
    "\n",
    "def get_dataset(dataset_name):\n",
    "    data = Dataset()\n",
    "    if dataset_name=='20NG':\n",
    "        data.fetch_dataset(\"20NewsGroup\")\n",
    "        \n",
    "    elif dataset_name=='BBC_news':\n",
    "        data.load_custom_dataset_from_folder(data_dir + \"/BBC_news\")\n",
    "        \n",
    "    elif dataset_name=='Wiki40B':\n",
    "        data.load_custom_dataset_from_folder(data_dir + \"/Wiki40B\")\n",
    "        \n",
    "    elif dataset_name=='AllNews':\n",
    "        data.load_custom_dataset_from_folder(data_dir + \"/AllNews\")\n",
    "    else:\n",
    "        raise Exception('Missing Dataset name...!!!')\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_model(model_name, num_topics, dataset_name, use_partitions, theta_dropout, enc_dropout, num_epochs=30):\n",
    "    \n",
    "    if model_name=='ETM':\n",
    "        model = ETM(num_topics=num_topics,\n",
    "                    num_epochs=num_epochs,\n",
    "                    theta_dropout=theta_dropout,\n",
    "                    enc_dropout=enc_dropout,\n",
    "                    train_embeddings=True,\n",
    "                    use_partitions=use_partitions)\n",
    "        \n",
    "    elif model_name=='CTM_combined':\n",
    "        model = CTM(num_topics=num_topics,\n",
    "                    num_epochs=num_epochs,\n",
    "                    theta_dropout=theta_dropout,\n",
    "                    enc_dropout=enc_dropout,\n",
    "                    bert_path='./bert/{}/'.format(dataset_name),\n",
    "                    bert_model='paraphrase-distilroberta-base-v2',\n",
    "                    inference_type=\"combined\",\n",
    "                    use_partitions=use_partitions)\n",
    "    \n",
    "    elif model_name=='ProdLDA':\n",
    "        model = ProdLDA(num_topics=num_topics,\n",
    "                        use_partitions=use_partitions,\n",
    "                        num_epochs=num_epochs,\n",
    "                        theta_dropout=theta_dropout,\n",
    "                        enc_dropout=enc_dropout,)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Missing Model name...!!!')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5094de9",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edacdda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-26T15:07:58.516787Z",
     "start_time": "2023-02-26T14:55:03.968935Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from random import seed, randint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "seeds = [randint(0, 2e3) for _ in range(10)]\n",
    "n_topics = [20, 50, 100]\n",
    "models = ['CTM_combined', 'ProdLDA', 'ETM']\n",
    "datasets = ['20NG', 'BBC_news', 'Wiki40B', 'AllNews']\n",
    "use_partitions = [True]\n",
    "theta_dropout = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "enc_dropout = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "results = {\n",
    "    'Dataset': [],\n",
    "    'Seed': [],\n",
    "    'K': [],\n",
    "    'Partition': [],\n",
    "    'ThetaDrop': [],\n",
    "    'EncodingDrop': [],\n",
    "    'Model':[],\n",
    "    'NPMI': [],\n",
    "    'TD': [],\n",
    "    'Accuracy':[]\n",
    "}\n",
    "\n",
    "\n",
    "td = TopicDiversity(topk=10)\n",
    "irbo = InvertedRBO(topk=10)\n",
    "\n",
    "for m in models:\n",
    "    for k in n_topics:\n",
    "        for seed in seeds:\n",
    "            for partition in use_partitions:\n",
    "                for e_drop in enc_dropout:\n",
    "                    for t_drop in theta_dropout:\n",
    "                        for d in datasets:\n",
    "                            data = get_dataset(d)\n",
    "\n",
    "                            print(\"-\"*100)\n",
    "                            print('Dataset:{}, Model:{}, K={}, seed={}, partition={}, enc_dropout={}, theta_dropout={}'.format(d, m, k, seed, partition, e_drop, t_drop))\n",
    "                            print(\"-\"*100)\n",
    "\n",
    "                            random.seed(seed)\n",
    "                            torch.random.manual_seed(seed)\n",
    "\n",
    "                            model = get_model(model_name=m,\n",
    "                                              num_topics=k,\n",
    "                                              dataset_name=d,\n",
    "                                              use_partitions=partition,\n",
    "                                              enc_dropout=e_drop,\n",
    "                                              theta_dropout=t_drop,\n",
    "                                             )\n",
    "\n",
    "                            output = model.train_model(dataset=data)\n",
    "                            del model\n",
    "                            torch.cuda.empty_cache()\n",
    "                            #Hyperparams:\n",
    "                            results['Dataset'].append(d)\n",
    "                            results['Model'].append(m)\n",
    "                            results['K'].append(k)\n",
    "                            results['Seed'].append(seed)\n",
    "                            results['Partition'].append(partition)\n",
    "                            results['EncodingDrop'].append(e_drop)\n",
    "                            results['ThetaDrop'].append(t_drop)\n",
    "                            #############\n",
    "                            if partition==True:\n",
    "                                #classification:\n",
    "                                #Accuracy\n",
    "                                try:                                    \n",
    "                                    accuracy = AccuracyScore(data)\n",
    "                                    results['Accuracy'].append(accuracy.score(output))\n",
    "                                except:\n",
    "                                    results['Accuracy'].append(0.0)\n",
    "                            #############\n",
    "                            #Coherence Scores:\n",
    "                            npmi = Coherence(texts=data.get_corpus(), measure='c_npmi')\n",
    "                            results['NPMI'].append(npmi.score(output))\n",
    "                            del npmi\n",
    "                            #############\n",
    "                            #Topic Diversities:\n",
    "                            results['TD'].append(td.score(output))                            \n",
    "                            clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8079e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-26T15:08:00.652074Z",
     "start_time": "2023-02-26T15:08:00.649500Z"
    }
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed4078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "451px",
    "width": "471px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
